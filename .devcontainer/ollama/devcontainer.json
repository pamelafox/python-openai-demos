// For format details, see https://aka.ms/devcontainer.json. For config options, see the README at:
// https://github.com/microsoft/vscode-dev-containers/tree/v0.245.0/containers/python-3
{
    "name": "python-openai-demos (Ollama)",
    "image": "mcr.microsoft.com/devcontainers/python:3.11-bullseye",
    "features": {
        "ghcr.io/prulloac/devcontainer-features/ollama:1": {}
    },
    // Configure tool-specific properties.
    "customizations": {
        // Configure properties specific to VS Code.
        "vscode": {
            // Set *default* container specific settings.json values on container create.
            "settings": {
                "python.defaultInterpreterPath": "/usr/local/bin/python"
            },

            // Add the IDs of extensions you want installed when the container is created.
            "extensions": [
                "ms-python.python",
                "charliermarsh.ruff",
                "ms-python.black-formatter"
            ]
        }
    },

    // Use 'postCreateCommand' to run commands after the container is created.
    "postCreateCommand": "pip3 install --user -r requirements-dev.txt && cp .env.sample.ollama .env && ollama pull llama3.1",

    // Comment out to connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.
    "remoteUser": "vscode",

    // Required to handle Ollama models
    "hostRequirements": {
        "memory": "64gb"
    }
}
